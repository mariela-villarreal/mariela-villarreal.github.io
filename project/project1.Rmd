---
title: 'Project 1: Exploratory Data Analysis'
author: Mariela Villarreal, mmv798
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```

## Netflix in All Kinds of Weather
###Introduction
  For my project, I was interested in seeing if my Netflix watching habits were affected in the weather in Laredo, TX (my hometown). The weather in Laredo is pretty predictable; it's usually hot, and it rains every once in a while. I wasn't sure which results I could expect to find, but I knew that I would probably watch TV with greater frequency when it was hotter outside. 
  
  I downloaded my viewing history from Netflix and decided to add a variable for the genre of each movie or TV show that I had watched. The CSV that I uploaded to R had the date that I watched a certain show/movie, the title, and the genre. The weather data that I downloaded was from the National Centers for Environmental Information. It contained weather information taken from a station at the Laredo International Airport from July 2019 - July 2020. The weather dataset contained variables for the Daily Average Dry Bulb Temperature, which is considered to be the temperature of the air and the "true thermodynamic temperature", according to Wikipedia. The maximum and minimum dry bulb temperature are given. The dataset also includes the air pressure, daily precipitation, daily cooling degree days, and daily heating degree days. Cooling and heating degree days are actually more of a measure of energy consumption. These values indicate the number of degrees either above or below 65 degrees, with cooling degree days being degrees above 65 and heating degree days being degrees below 65. The "cooling" and "heating" refer to the idea that people in a building would want the building to be cooled or heated when the temperature goes above or below 65, respectively. The two datasets were then joined based on date.

### Tidying
Both of the datasets were tidy. However, I needed to clean up the weather dataset quite a bit by removing several columns that were irrelevant (such as variables for snow). The code below shows how I read the CSV in and set the date as a character (because I needed to join on this variable and the date for the Netflix data was also a character). I then filtered based on the report type; "SOD" gave the daily average of all the variables, instead of the hourly data. Next, I selected only the variables that had data. All of the columns removed contained only NAs, but using na.omit() left me with a completely empty dataset. This required me to individually remove every column that was empty. Finally, I cleaned up the value for date, removing the time stamp that was included. I went from a dataset with 124 variable to one with 8. 

```{R}
library(readr)
weather <- read_csv("weather.csv", col_types = cols(DATE = col_character())) #Reading the dataset in
library(tidyverse)
library(dplyr)
weather <- weather %>% filter(REPORT_TYPE=="SOD") #Filtering based on report type

weather_data <- weather %>% select(DATE, contains("Daily"), -contains("Snow"), -DailyAverageDewPointTemperature,-DailyDepartureFromNormalAverageTemperature,-DailyAverageRelativeHumidity,-DailyAverageSeaLevelPressure,
-DailyAverageWetBulbTemperature,-DailyAverageWindSpeed,-DailyDepartureFromNormalAverageTemperature,-DailyPeakWindDirection,
-DailyPeakWindSpeed,-DailySustainedWindDirection,-DailySustainedWindSpeed,-DailyWeather) #Removing irrelevant columns

weather_data <- weather_data %>% separate(DATE, sep=10, into=c("Date","Other")) #Separating the date and time stamp
weather_data <- weather_data  %>% select(-Other) %>% glimpse() #Removing the time stamp


```

###Joining/Merging
I read in the Netflix history dataset and joined the two datasets by date using full_join. I chose to do a full_join so that I could retain all of the information from both datasets. The two datasets were joined based on date, and using any other join would result in my losing the other variables of one of the datasets. I then removed any NAs from the joined dataset.

```{R}
ntflx_hist <- read_csv("NetflixViewingHistory-edited.csv", col_types = cols(Date = col_character())) #Reading the dataset in. 

joined <- weather_data %>% full_join(ntflx_hist, by= c("Date" = "Date"))  #Joining based on date
joined2 <- joined %>% na.omit() #Removing NAs
```


Next, I decided to create a new column so that I could distinguish between the movies and the TV shows. This was somewhat difficult, since the titles of the TV shows were not uniform. To denote the season of the show, some programs used "Season", and others used "Collection", "Chapter", or "Series". I separated the title of the program based on these words. I had to download the dataset and make a few adjustments for the Limited Series, whose names were different, in Excel. I read this file back in and made sure that each of the numerical variables were set as numerical in R. I also deleted the row "X1" that was included after I read the dataset back into R. I was then able to further separate the name of the program into Season and Episode. Any movie that I saw would have an "NA" for Episode.  



```{R}
joined3 <- joined2 %>% separate(Title, sep="Season|Collection|Chapter|Series", into=c("Title","Other")) #Separating title into season/episode ("Other")
write.csv(joined3, "joined3.csv") #Writing the CSV so that I could download it
joined3 <- read_csv("joined3.csv", col_types = cols(DailyAverageDryBulbTemperature = col_number(), DailyAverageStationPressure = col_number(), DailyCoolingDegreeDays = col_number(), DailyHeatingDegreeDays = col_number(), DailyMaximumDryBulbTemperature=col_number(), DailyMinimumDryBulbTemperature = col_number(), X1 = col_character(), DailyPrecipitation=col_number())) %>% glimpse() #Reading the dataset back in and adjusting the columns

joined4 <- joined3 %>% separate(Other, sep=":", into=c("Season", "Episode")) #Separating season and episode
joined5 <- joined4 %>% select(-X1) #Removing a column that was added by Excel
```



It was at this point that I realized I hadn't been in Laredo during the whole time the dataset covers. I sliced out rows that covered the time that I was away from Laredo and removed it from the dataset by doing an anti_join. 



```{R}
stuff<- joined5 %>% slice(142:215) #Cutting out the days that I was not in Laredo
joined6 <- joined5 %>% anti_join(stuff) %>% glimpse() #Doing an anti_join to remove the rows 
```

###Wrangling
With my finalized dataset, I created a new variable by converting DailyPrecipitation in inches to millimeters by multiplying the values by 25.4, which is the conversion factor. I also performed my summary statistics before and after grouping by Genre. The average, standard deviation, minimum, maximmum, and variance of each numeric value in the dataset are shown below. This past year was pretty hot in Laredo, with the hottest daily maximum tempeature being 110 degrees Fahrenheit. It also rarely rained, with the average amoung of precipitation being 0.07 inches. The air pressure also did not vary much; standard deviation and variance were both very low. When grouped by genre, a lot of information was created. To summarize a few of the interesting points, the days on which I watched biographies had, on average, the greatest daily average dry bulb temperature, 91 degrees Fahrenheit. Also, days that I spent watching reality TV were days that had the highest average daily precipitation, 0.25 inches. 

```{R}
joined6 <- joined6 %>% mutate(mmDailyPrecip= DailyPrecipitation*25.4) #Creating a new variable

joined6 %>% summarize_if(is.numeric, c(Mean=mean, Sd=sd, Min=min, Max=max, Var=var),na.rm=T) %>% pivot_longer(contains("_")) %>% separate(name, into=c("Variable", "Statistic")) %>% pivot_wider(names_from="Statistic", values_from="value") #Creating summary statistics




joined6 %>% group_by(Genre) %>% summarize_if(is.numeric, c(Mean=mean, Sd=sd, Min=min, Max=max, Var=var),na.rm=T) %>% pivot_longer(contains("_")) %>% separate(name, into=c("Variable", "Statistic")) %>% pivot_wider(names_from="Statistic", values_from="value") #Creating summary summary statistics, grouping by genre
 
joined6 %>% group_by(Genre) %>% summarize_if(is.numeric, c(Mean=mean, Sd=sd, Min=min, Max=max, Var=var),na.rm=T) %>% pivot_longer(contains("_")) %>% separate(name, into=c("Variable", "Statistic")) %>% pivot_wider(names_from="Statistic", values_from="value") %>% filter(Variable=="DailyAverageDryBulbTemperature") %>% select(Mean) %>% arrange(desc(Mean)) #Looking at mean DailyAverageDryBulbTemperature based on genre

joined6 %>% group_by(Genre) %>% summarize_if(is.numeric, c(Mean=mean, Sd=sd, Min=min, Max=max, Var=var),na.rm=T) %>% pivot_longer(contains("_")) %>% separate(name, into=c("Variable", "Statistic")) %>% pivot_wider(names_from="Statistic", values_from="value") %>% filter(Variable=="DailyPrecipitation") %>%select(Mean) %>% arrange(desc(Mean)) #Looking at mean DailyPrecipiration based on genre
 
```


The data required a bit more exploration. I first looked at how many movies/TV shows from each genre I had watched. The genre that I saw the most of was comedy, with 150 shows/movies. My favorite genre is Horror, so I wanted to know more about what I had watched and what the weather was like on days that I watched horror movies/shows. On the days that I watched horror movies, the mean daily average temperature was only 81 degrees, and it rained very little (an average of 0.007 inches). I also had an interest to investigate the days that had the hottest daily maximum dry bulb temperature and found that this day was July 13, 2020. On this day, I watched two incredibly long movies (Inglourious Basterds is 2 1/2 hours long and Fiddler on the Roof is 3 hours long). I then wanted to see how many movies I had watched. The movies contain an "NA" in the episode column, so I created a function to add the number of NAs and selected Episode to count the number of movies. During this time, I watched 131 movies. I grouped the data by date and counted the number of rows for each date to see which day I spent watching the most TV; this date happened to be July 29, 2020. On this day, the average temperature was actually very nice - 84 degrees. The show that I have watched the most of is Parks and Recreation, and on the days that I watched Action/Adventure, Comedy, Competition, and Drama, the maxiumum average temperature was 95 degrees. 

```{R}
joined6 %>% group_by(Genre) %>% summarize(Numberrows=n()) %>% arrange(desc(Numberrows)) #Counting the number of shows/movies in each genre


joined6 %>% filter(Genre=="Horror") %>% select(Title) #Listing the horror shows/movies
joined6%>% filter(Genre =="Horror") %>% summarize_if(is.numeric, c(Mean=mean, Sd=sd, Min=min, Max=max, Var=var),na.rm=T) %>% pivot_longer(contains("_")) %>% separate(name, into=c("Variable", "Statistic")) %>% pivot_wider(names_from="Statistic", values_from="value") #Creating summary statistics for horror shows/movies


joined6  %>% filter(DailyMaximumDryBulbTemperature== max(DailyMaximumDryBulbTemperature)) #Filtering days where the DailyMaximumDryBulbTemperature was the greatest
joined6 %>% filter(Date=="2020-07-13") %>% select(Title) #Listing the shows/movies I saw when the DailyMaximumDryBulbTemperature was the greatest

NumberMovie <- function(x)sum(is.na(x))  #Creating a function to count the number of NAs 
joined6 %>% select(Episode)  %>% summarize_all(NumberMovie) #Counting the number of NAs in the Episode column/counting number of movies seen


joined6 %>% group_by(Date) %>% summarize(NumberDays=n()) %>% arrange(desc(NumberDays)) #Listing the number of shows/movies I watched on each day
joined6 %>% filter(Date=="2020-07-29") #Looking into the day where I watched the most TV 


joined6 %>% group_by(Genre,Title) %>% summarize(NumberGenre=n()) %>% arrange(desc(NumberGenre)) #Listing what show/movie I had seen the most
joined6 %>% group_by(Genre) %>% summarize(Max=max(DailyAverageDryBulbTemperature)) %>% arrange(desc(Max)) #Looking into what genre I watched when the DailyAverageDryBulbTemperature was the highest

```

### Visualizations

To show the correlation between all of my numeric variables, I created a correlation heatmap. As shown, the variables with the highest correlation are  DailyAverageDryBulbTemperature with DailyCooolingDegreeDays (0.98). This makes sense, since cooling degree days are calculated based on the number of degrees above or below 65 degrees. 
```{R}
cormat <- joined6 %>% select_if(is.numeric) %>% cor(use="pair") #Creating a correlation matrix
tidycor <- cormat %>% as.data.frame %>% rownames_to_column("var1") %>%
pivot_longer(-1,names_to="var2",values_to="correlation") #Tidying correlation matrix

tidycor %>% arrange(desc(correlation)) #Correlation Data

tidycor%>%ggplot(aes(var1,var2,fill=correlation))+geom_tile()+
geom_text(aes(label=round(correlation,2)))+
xlab("")+ylab("")+coord_fixed() + theme(axis.text.x= element_text(angle=45, hjust = 1)) + ggtitle("Correlation Heatmap") #Creating correlation heatmap

```


I was interested to see the relationship between DailyAverageDryBulbTemperature and DailyAverageStationPressure. The graph below shows the linear regression for these values and the negative relationship they have. Each line on the graph represents a genre, and the genre with the strongest negative relationship (steepest slope) appears with Drama movies/shows. The weakest negative relationship appears with Romance movies/shows. Interestingly, it appears that Musicals actually have a slightly positive relationship between pressure and temperature. 

```{R}
joined6 %>% ggplot(aes(DailyAverageDryBulbTemperature,DailyAverageStationPressure)) + geom_smooth(method=lm, aes(color=Genre)) +geom_point(aes(color=Genre)) + ggtitle("Relationship between Temperature and Pressure in Laredo, Texas") + theme_dark() + ylab(label = "Daily Average Station Pressure") +xlab(label = "Daily Average Dry Bulb Temperature") #Linear regresstion relationship between DailyAverageDryBulbTemperature and DailyAverageStationPressur
```


The relationship between average DailyPrecipitation and DailyAverageDryBulbTemperature is shown below. In Laredo, it doesn't rain very often (which is evident by the number of points at 0 inches of rain). However, the highest average daily precipitation occurred with a reality TV show. There is a slight negative correlation that can be seen between these two variables, indicating that there is less rain when it is hotter outside. 

```{R}
joined6 %>% ggplot(aes(DailyAverageDryBulbTemperature, DailyPrecipitation, color=Genre)) + geom_point(aes(y=DailyPrecipitation), stat="summary", fun="mean") + xlim(45,95) +ylim(-0.1,1.75) + ggtitle("Relationship between Temperature and Average Temperature in Laredo, Texas") +ylab(label = "Average Daily Precipitation") +xlab(label = "Daily Average Dry Bulb Temperature") #Scatterplot showing relationship between DailyPrecipitation and DailyAverageDryBulbTemperature
```

### Dimensionality Reduction

For my data, I chose to run PCA on my numerical variables. As seen in the summary of the loadings, the PCs that were kept were the first two (Comp.1 and Comp.2), since, according to the cumulative proportion, they account for 85% of the variance. Higher scores for PC1 (Comp.1) mean lower station pressure, precipitation and heating degree days, but higher temperature (average, maximum, and minimum) and cooling degree days. Higher scores for PC2 (Comp.2) mean lower cooling degree days and higher precipitation. These relationships makes sense based on the correlation heatmap and the relationships shown in the graphs above.    
 
```{R}
joined7 <- joined6 %>% select(-Genre,-Episode,-Season) %>% na.omit() #This captures only the numeric variables and removes any NAs from the data. 
joined_nums <- joined7 %>% select_if(is.numeric) %>% scale   #This scales the data (divides by the standard deviation)
rownames(joined_nums) <- joined7$Title   
joined_PCA <-princomp(joined_nums) #This performs the actual PCA
summary(joined_PCA, loadings=T)
```

The data, with respect to PC1 and PC2, is shown in the graph below. The data contains many points that are higher for PC1 and around zero for PC2. There are a few points that are extreme for PC1 (on the lower end) and PC2 (on the higher end); these points are investigated later.  

```{R}
joined7df<-data.frame(Date=joined7$Date, PC1=joined_PCA$scores[, 1],PC2=joined_PCA$scores[, 2]) #this creates a dataframe from the PCA data
joined7df %>% ggplot(aes(PC1,PC2)) +geom_point() + ggtitle("Plot of PC1 vs PC2") +xlim(-10,2.5) +ylim(-4,10) #Plot of PC1 and PC2
```

The graph below shows the variables that contribute to both PCs. You can see, that the main driver for PC2 is DailyPrecipitation, while temperature (average, minimum, and maximum) contribute to a posisive PC1 score. 
```{R}
joined_PCA$loadings[1:7, 1:2] %>% as.data.frame %>% rownames_to_column %>%
ggplot() + geom_hline(aes(yintercept=0), lty=2) +
geom_vline(aes(xintercept=0), lty=2) + ylab("PC2") + xlab("PC1") +
geom_segment(aes(x=0, y=0, xend=Comp.1, yend=Comp.2), arrow=arrow(), col="red") +
geom_label(aes(x=Comp.1*1.1, y=Comp.2*1.1, label=rowname))+ ylim(-1,1) + xlim(-0.75,0.75) #Plot of loadings
```

The extreme points shown in the Plot of PC1 vs. PC2 are investigated here. The points that are on the extreme low end of PC1 belong to several episodes of the show "The End of the F-ing World", "Jenny Slate:Stage Fright", and an episode of "The Great British Baking Show: The Holidays". The days that I watched these shows were cold, with high heating degree days and low precipitation. The points that are on the extreme high end of PC1 correspond with several episodes of a ridiculous Australian reality TV show called "Yummy Mummies" that I binged over the course of several days. On these days, there was quite a lot of rain and the temperatures were low (with zero heating degree days).

```{R}
joined_PCA$scores[,1:4] %>% as.data.frame %>% top_n(-3, Comp.1) #Exploring the lowest three PC1 scores
joined7 %>% filter(Title%in%c("The End of the F***ing World:","Jenny Slate: Stage Fright","The Great British Baking Show: Holidays:")) #Exploring days with lowest PC1 scores
joined_PCA$scores[,1:4] %>% as.data.frame %>% top_n(3, Comp.2) #Exploring the highest three PC2 scores
joined7 %>% filter(Title=="Yummy Mummies:") #Exploring days with highest PC2 scores. 
```


...





